name: Spark CI

on:
  push:
    branches:
      - main
    paths:
      - 'Custom_folder/**'

jobs:
  build:
    name: Build and Test
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v2

    - name: Set up Java
      uses: actions/setup-java@v2
      with:
        java-version: '11'  
        distribution: 'adopt'  

    - name: Set up Spark
      run: | 
        wget https://dlcdn.apache.org/spark/spark-3.4.1/spark-3.4.1-bin-hadoop3.tgz
        tar xzf spark-3.4.1-bin-hadoop3.tgz
        
    - name: Set up Environmetal Variables
      run: |
        export SPARK_HOME=$(pwd)/spark-3.4.1-bin-hadoop3
        export PATH=$PATH:$SPARK_HOME/bin
        echo "SPARK_HOME=$SPARK_HOME" >> $GITHUB_ENV
        echo "PATH=$PATH" >> $GITHUB_ENV

    - name: ls
      run: |
        ls

    - name: pwd
      run: |
        pwd

    - name: Get the current image tag
      id: get_image_tag
      run: echo "::set-output name=tag::$(cat Custom_folder/image_tag.txt)"

    - name: Increment the image tag
      id: increment_tag
      run: echo "::set-output name=tag::$(($(cat Custom_folder/image_tag.txt) + 1))" > Custom_folder/image_tag.txt

    - name: Build & Push Docker Image
      env:
        DOCKER_USERNAME: ${{ secrets.DOCKER_USERNAME }}
        DOCKER_TOKEN: ${{ secrets.DOCKER_TOKEN }}
      run: |
        IMAGE_TAG=${{ steps.increment_tag.outputs.tag }}
        echo IMAGE_TAG
        docker build -t psshri/spark-argocd-dev:appv1.$IMAGE_TAG .
        docker login -u "$DOCKER_USERNAME" -p "$DOCKER_TOKEN"
        docker push psshri/spark-argocd-dev:appv1.$IMAGE_TAG

    - name: Update image tag for the next run
      run: |
        IMAGE_TAG=${{ steps.increment_tag.outputs.tag }}
        echo $IMAGE_TAG > Custom_folder/image_tag.txt
    
    - name: Build and Test Spart code
      run: |
        cd Custom_folder
        $SPARK_HOME/bin/spark-submit word_count.py