name: Spark CI

on:
  push:
    branches:
      - main
    paths:
      - 'Custom_folder/**'

jobs:
  build:
    name: Build and Test
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v2

    - name: Set up Java
      uses: actions/setup-java@v2
      with:
        java-version: '11'  
        distribution: 'adopt'  

    - name: Set up Spark
      run: | 
        wget https://dlcdn.apache.org/spark/spark-3.4.1/spark-3.4.1-bin-hadoop3.tgz
        tar xzf spark-3.4.1-bin-hadoop3.tgz
        
    - name: Set up Environmetal Variables
      run: |
        export SPARK_HOME=$(pwd)/spark-3.4.1-bin-hadoop3
        export PATH=$PATH:$SPARK_HOME/bin
        echo "SPARK_HOME=$SPARK_HOME" >> $GITHUB_ENV
        echo "PATH=$PATH" >> $GITHUB_ENV

    - name: Build & Push Docker Image
      env:
        # DOCKER_USERNAME: ${{ secrets.DOCKER_USERNAME }}
        # DOCKER_TOKEN: ${{ secrets.DOCKER_TOKEN }}
        PACKAGE_WRITE: ${{ secrets.PACKAGE_WRITE }}
        GITHUB_USERNAME: ${{ secrets.USERNAME_GITHUB }}
      run: |
#        docker build -t psshri/spark-argocd-dev:latest .
#        docker login -u "$DOCKER_USERNAME" -p "$DOCKER_TOKEN"
#        docker push psshri/spark-argocd-dev:latest
        docker build -t ghcr.io/psshri/sparkapp-dev:latest .
        docker login ghcr.io -u "$GITHUB_USERNAME" -p "$PACKAGE_WRITE"
        docker push ghcr.io/psshri/sparkapp-dev:latest
    
    - name: Build and Test Spart code
      run: |
        cd Custom_folder
        $SPARK_HOME/bin/spark-submit word_count.py