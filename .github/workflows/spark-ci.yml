name: Spark CI

on:
  push:
    branches:
      - main
    paths-ignore:
      - 'k8s-config/**'
      - 'argocd-application.yaml'

jobs:
  build:
    name: Build and Test
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v2

    - name: Set up Java
      uses: actions/setup-java@v2
      with:
        java-version: '11'  
        distribution: 'adopt'  

    - name: Set up Spark
      run: | 
        wget https://dlcdn.apache.org/spark/spark-3.4.1/spark-3.4.1-bin-hadoop3.tgz
        tar xzf spark-3.4.1-bin-hadoop3.tgz
        
    - name: Set up Environmetal Variables
      run: |
        export SPARK_HOME=$(pwd)/spark-3.4.1-bin-hadoop3
        export PATH=$PATH:$SPARK_HOME/bin
        echo "SPARK_HOME=$SPARK_HOME" >> $GITHUB_ENV
        echo "PATH=$PATH" >> $GITHUB_ENV
        
    - name: Build & Push Docker Image
      env:
        DOCKER_USERNAME: ${{ secrets.DOCKER_USERNAME }}
        DOCKER_TOKEN: ${{ secrets.DOCKER_TOKEN }}
      run: |
#        docker build -t sparkapp:v1.0 .    
        docker build -t psshri/spark-argocd:appv3.1 .
        docker login -u "$DOCKER_USERNAME" -p "$DOCKER_TOKEN"
        docker push psshri/spark-argocd:appv3.1

#     - name: Build and Test Spark Code
#       run: |
#         cd Custom_folder
#         $SPARK_HOME/bin/spark-submit word_count.py   